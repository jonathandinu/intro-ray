{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ray-train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clearspandex/distributed-ml-ray/blob/main/notebooks/ray_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SP8fcPUvSpb"
      },
      "outputs": [],
      "source": [
        "!pip install ray"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "import ray.train as train\n",
        "from ray.train.trainer import Trainer\n",
        "from ray.train.callbacks import JsonLoggerCallback\n",
        "\n",
        "ray.init()\n",
        "\n",
        "# in practice you will want to spin up a multi-GPU cluster: https://docs.ray.io/en/latest/cluster/quickstart.html\n",
        "trainer = Trainer(backend='torch', num_workers=2, use_gpu=False)\n",
        "trainer.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bd7PKdZVg5K",
        "outputId": "1103bf71-da5e-4864-9302-c2e613a5a316"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-01 06:32:28,586\tINFO trainer.py:243 -- Trainer logs will be logged in: /root/ray_results/train_2022-07-01_06-32-28\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m 2022-07-01 06:32:37,720\tINFO torch.py:347 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m 2022-07-01 06:32:37,889\tINFO torch.py:347 -- Setting up process group for: env:// [rank=1, world_size=2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ray Train"
      ],
      "metadata": {
        "id": "FCL9IOoFCmEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model architecture\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stack = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(6, 16, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Linear(256, 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, 10)\n",
        "        )\n",
        "                \n",
        "    def forward(self, x):\n",
        "        return self.stack(x)"
      ],
      "metadata": {
        "id": "Qa4mdIKvW00v"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"~/data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"~/data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "hhVLFVc0Nq6A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup function to train and eval for one epoch\n",
        "\n",
        "def train_epoch(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset) // train.world_size()\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # backpropagate gradients\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "\n",
        "            # print logs to local node\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def validate_epoch(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset) // train.world_size()\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    # put PyTorch network in eval mode\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            \n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(\n",
        "        f\"Test Error: \\n \"\n",
        "        f\"Accuracy: {(100 * correct):>0.1f}%, \"\n",
        "        f\"Avg loss: {test_loss:>8f} \\n\"\n",
        "    )\n",
        "    return test_loss"
      ],
      "metadata": {
        "id": "wow5Yj2JOOQo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_func():\n",
        "    batch_size = 64\n",
        "    epochs = 5\n",
        "\n",
        "    worker_batch_size = batch_size // train.world_size()\n",
        "\n",
        "    # setup DataLoaders\n",
        "    train_dataloader = DataLoader(training_data, batch_size=worker_batch_size)\n",
        "    train_dataloader = train.torch.prepare_data_loader(train_dataloader)\n",
        "\n",
        "    test_dataloader = DataLoader(test_data, batch_size=worker_batch_size)\n",
        "    test_dataloader = train.torch.prepare_data_loader(test_dataloader)\n",
        "\n",
        "    # setup model\n",
        "    net = LeNet()\n",
        "    model = train.torch.prepare_model(net)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for i in range(epochs):\n",
        "        train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
        "        loss = validate_epoch(test_dataloader, model, loss_fn)\n",
        "        train.report(loss=loss)\n",
        "        losses.append(loss)\n",
        "\n",
        "    return losses"
      ],
      "metadata": {
        "id": "m_IXda7lDdGO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = trainer.run(\n",
        "    train_func=train_func,\n",
        "    callbacks=[JsonLoggerCallback()],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZHMOZMWHj3r",
        "outputId": "4a14c9d3-d628-4c7a-832e-0ca38a8e7f76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-01 06:38:20,355\tINFO trainer.py:249 -- Run results will be logged in: /root/ray_results/train_2022-07-01_06-32-28/run_002\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m 2022-07-01 06:38:20,953\tINFO torch.py:98 -- Moving model to device: cpu\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m 2022-07-01 06:38:20,953\tINFO torch.py:132 -- Wrapping provided model in DDP.\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m 2022-07-01 06:38:20,949\tINFO torch.py:98 -- Moving model to device: cpu\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m 2022-07-01 06:38:20,950\tINFO torch.py:132 -- Wrapping provided model in DDP.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.298295  [    0/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.301855  [    0/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.305949  [ 3200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.306239  [ 3200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.326731  [ 6400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.289704  [ 6400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.317367  [ 9600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.312324  [ 9600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.303359  [12800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.284207  [12800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.298878  [16000/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.303739  [16000/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.305996  [19200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.300008  [19200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.309179  [22400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.275398  [22400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.294369  [25600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.310738  [25600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.311705  [28800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.315037  [28800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m Test Error: \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m  Accuracy: 9.6%, Avg loss: 2.302539 \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.295537  [    0/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m Test Error: \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m  Accuracy: 10.4%, Avg loss: 2.301392 \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.299761  [    0/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.303295  [ 3200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.303383  [ 3200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.320634  [ 6400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.288155  [ 6400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.312969  [ 9600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.308292  [ 9600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.301049  [12800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.284784  [12800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.295872  [16000/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.300595  [16000/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.302763  [19200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.297333  [19200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.305525  [22400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.274760  [22400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.291592  [25600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.307348  [25600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.308116  [28800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.310855  [28800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m Test Error: \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m  Accuracy: 9.7%, Avg loss: 2.299261 \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m Test Error: \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m  Accuracy: 10.5%, Avg loss: 2.298112 \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.291773  [    0/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.297513  [    0/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.299831  [ 3200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.300050  [ 3200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.313783  [ 6400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.285780  [ 6400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.308173  [ 9600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.303807  [ 9600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.297936  [12800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.285173  [12800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.291467  [16000/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.296246  [16000/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.298513  [19200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.293525  [19200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.301465  [22400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.271797  [22400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.287740  [25600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.303873  [25600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.303430  [28800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.305257  [28800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m Test Error: \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m  Accuracy: 14.9%, Avg loss: 2.294414 \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.286288  [    0/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m Test Error: \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m  Accuracy: 15.2%, Avg loss: 2.293164 \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.294608  [    0/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.294825  [ 3200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.295457  [ 3200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.305211  [ 6400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.280940  [ 6400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.301760  [ 9600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.297371  [ 9600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.292779  [12800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.283415  [12800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.284753  [16000/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.289649  [16000/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.292258  [19200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.287388  [19200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.294907  [22400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.266210  [22400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.280893  [25600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.297792  [25600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.297414  [28800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.298076  [28800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m Test Error: \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m  Accuracy: 18.6%, Avg loss: 2.286796 \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.276307  [    0/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m Test Error: \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m  Accuracy: 19.2%, Avg loss: 2.285339 \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.288821  [    0/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.286987  [ 3200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.288151  [ 3200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.292215  [ 6400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.272647  [ 6400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.292427  [ 9600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.287876  [ 9600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.283934  [12800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.279334  [12800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.272305  [16000/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.277658  [16000/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.282080  [19200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.276531  [19200/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.283684  [22400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.253291  [22400/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.266741  [25600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.286736  [25600/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m loss: 2.286287  [28800/30000]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m loss: 2.284638  [28800/30000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.shutdown()\n",
        "print(f\"Loss results: {result}\")"
      ],
      "metadata": {
        "id": "hSgKOBgAH9fB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1dd29b-9c09-4fcc-f8b9-a4aa194b1fb1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m Test Error: \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m  Accuracy: 21.0%, Avg loss: 2.272009 \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2846)\u001b[0m \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m Test Error: \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m  Accuracy: 21.2%, Avg loss: 2.270097 \n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=2845)\u001b[0m \n",
            "Loss results: [[2.3013921482547834, 2.298111924699917, 2.2931637688047566, 2.2853394526584894, 2.2700969322471862], [2.3025391997805067, 2.2992611675505428, 2.294413719966913, 2.2867955037742664, 2.272008587600319]]\n"
          ]
        }
      ]
    }
  ]
}